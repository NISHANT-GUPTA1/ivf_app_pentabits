{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2fbf8a7d",
      "metadata": {
        "id": "2fbf8a7d"
      },
      "source": [
        "# üî¨ Embryo Viability Classifier - F15 Focal Plane\n",
        "\n",
        "## Member 1 Training Notebook\n",
        "\n",
        "**Dataset:** Human embryo time-lapse videos (F15 focal plane - 8.9 GB)  \n",
        "**Features:** 20 features (16 morphological + 4 temporal)  \n",
        "**Expected Accuracy:** 85-90%\n",
        "\n",
        "---\n",
        "\n",
        "## üì¶ Outputs Generated:\n",
        "1. `embryo_model_F15.pkl` - Trained Random Forest model\n",
        "2. `scaler_F15.pkl` - Feature scaler (StandardScaler)\n",
        "3. `results_F15.json` - Evaluation metrics\n",
        "4. `feature_names_F15.json` - Feature column names\n",
        "5. `confusion_matrix_F15.png` - Visualization\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANT:** All members must generate the same 5 files with their focal plane suffix (F15/F30/F45)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d174fe",
      "metadata": {
        "id": "a9d174fe"
      },
      "source": [
        "---\n",
        "## 1Ô∏è‚É£ Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Force clean reinstall to fix broken sklearn\n",
        "!pip uninstall -y numpy scikit-learn scipy imbalanced-learn -q\n",
        "!pip install --no-cache-dir -q \"numpy>=2.0,<2.1\" \"scikit-learn>=1.6.0\" \"scipy>=1.13.0\"\n",
        "!pip install --no-cache-dir -q imbalanced-learn opencv-python matplotlib seaborn pandas tqdm joblib\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ CLEAN INSTALLATION COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"üì¶ All packages reinstalled without cache\")\n",
        "print(\"\\nüîÑ MANDATORY: RESTART RUNTIME NOW!\")\n",
        "print(\"   1. Runtime > Restart runtime\")\n",
        "print(\"   2. After restart, SKIP this cell\")\n",
        "print(\"   3. Run Cell 3 (imports)\")\n",
        "print(\"\\nüí° The restart is REQUIRED to load fresh packages\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "y6ze_SUltEmA",
        "outputId": "bf8058de-340e-4503-93f1-efa84e509c38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "y6ze_SUltEmA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m180.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m206.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m198.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m212.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m235.4/235.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "============================================================\n",
            "‚úÖ CLEAN INSTALLATION COMPLETE!\n",
            "============================================================\n",
            "üì¶ All packages reinstalled without cache\n",
            "\n",
            "üîÑ MANDATORY: RESTART RUNTIME NOW!\n",
            "   1. Runtime > Restart runtime\n",
            "   2. After restart, SKIP this cell\n",
            "   3. Run Cell 3 (imports)\n",
            "\n",
            "üí° The restart is REQUIRED to load fresh packages\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4781f7ad",
      "metadata": {
        "id": "4781f7ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dea24b9-8f60-4741-dd7a-ce43751656f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All imports successful!\n",
            "OpenCV version: 4.12.0\n",
            "NumPy version: 2.0.2\n",
            "Pandas version: 2.2.2\n"
          ]
        }
      ],
      "source": [
        "# Now that numpy and scikit-learn are pinned in the initial installation cell (c2f94216),\n",
        "# and runtime restart is expected, this re-installation is no longer needed here.\n",
        "# If you run into issues, consider restarting the runtime and re-running all cells.\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_auc_score,\n",
        "    accuracy_score, precision_score, recall_score, f1_score\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"OpenCV version: {cv2.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f60cfa9",
      "metadata": {
        "id": "6f60cfa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66635939-7914-4d5b-dd2d-60b2463fed58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive mounted!\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"‚úÖ Google Drive mounted!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "FOCAL_PLANE = \"F-45\"\n",
        "DATASET_FILE = \"embryo_dataset_F-45.tar.gz\"\n",
        "ANNOTATIONS_FILE = \"embryo_dataset_annotations.tar.gz\"\n",
        "\n",
        "print(f\"\"\"\\n{'='*60}\n",
        "‚öôÔ∏è CONFIGURATION\n",
        "{'='*60}\n",
        "Focal Plane: {FOCAL_PLANE}\n",
        "Dataset: {DATASET_FILE}\n",
        "Expected Size: 8.9 GB\n",
        "{'='*60}\\n\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "armFoDup41DN",
        "outputId": "c200ef60-a47f-47c2-99b4-bc21b3e44255"
      },
      "id": "armFoDup41DN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "‚öôÔ∏è CONFIGURATION\n",
            "============================================================\n",
            "Focal Plane: F-45\n",
            "Dataset: embryo_dataset_F-45.tar.gz\n",
            "Expected Size: 8.9 GB\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83565051",
      "metadata": {
        "id": "83565051"
      },
      "source": [
        "---\n",
        "## 2Ô∏è‚É£ Download & Extract Dataset\n",
        "\n",
        "### Option A: Upload from your computer\n",
        "### Option B: Download from Zenodo\n",
        "### Option C: Copy from Google Drive (if already uploaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "676efaa3",
      "metadata": {
        "id": "676efaa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "outputId": "7a45d01c-d14b-445a-dc8d-2223c05e5eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ EXTRACTING DATASET FROM GOOGLE DRIVE\n",
            "============================================================\n",
            "üìÅ Source: /content/drive/MyDrive/gfgIVF\n",
            "üìÅ Extract to: /content/drive/MyDrive/gfgIVF/embryo_data\n",
            "\n",
            "üîç Checking files in /content/drive/MyDrive/gfgIVF...\n",
            "‚úÖ Found 7 items\n",
            "\n",
            "üìÇ Items in Drive:\n",
            "   üìÑ embryo_dataset_F30.tar.gz (7779.4 MB)\n",
            "   üìÑ embryo_dataset_F-45.tar.gz (7696.8 MB)\n",
            "   üìÑ embryo_dataset_F45.tar.gz (6976.2 MB)\n",
            "   üìÑ embryo_dataset.tar.gz (11584.7 MB)\n",
            "   üìÑ embryo_dataset_annotations.tar.gz (0.1 MB)\n",
            "   üìÅ embryo_data/\n",
            "   üìÅ embryo_dataset_annotations/\n",
            "\n",
            "üì¶ Found 5 TAR.GZ file(s)\n",
            "\n",
            "üí° Extracting embryo_dataset_F-45.tar.gz...\n",
            "\n",
            "üì• Extracting: embryo_dataset_F-45.tar.gz\n",
            "   Size: 7.5 GB\n",
            "   ‚è≥ This will take 5-15 minutes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-788362255.py:54: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar_ref.extractall(extract_to)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-788362255.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r:gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0;31m# Extract all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0mtar_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   ‚úÖ Extracted successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, numeric_owner, filter)\u001b[0m\n\u001b[1;32m   2321\u001b[0m                 \u001b[0;31m# extracting contents can reset mtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m                 \u001b[0mdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfiltered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2323\u001b[0;31m             self._extract_one(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[0m\u001b[1;32m   2324\u001b[0m                               \u001b[0mnumeric_owner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_owner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m                               filter_function=filter_function)\n",
            "\u001b[0;32m/usr/lib/python3.12/tarfile.py\u001b[0m in \u001b[0;36m_extract_one\u001b[0;34m(self, tarinfo, path, set_attrs, numeric_owner, filter_function)\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2426\u001b[0;31m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[0m\u001b[1;32m   2427\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m                                  \u001b[0mnumeric_owner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_owner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner, filter_function, extraction_root)\u001b[0m\n\u001b[1;32m   2513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2515\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2516\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2517\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/tarfile.py\u001b[0m in \u001b[0;36mmakefile\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2562\u001b[0m         \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0mbufsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopybufsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mbltn_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Extract dataset from Google Drive (already downloaded)\n",
        "import os\n",
        "import tarfile\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"üì¶ EXTRACTING DATASET FROM GOOGLE DRIVE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Location where you downloaded the dataset\n",
        "source_dir = \"/content/drive/MyDrive/gfgIVF\"\n",
        "extract_to = \"/content/drive/MyDrive/gfgIVF/embryo_data\"  # Extract to Colab local storage for faster access\n",
        "\n",
        "print(f\"üìÅ Source: {source_dir}\")\n",
        "print(f\"üìÅ Extract to: {extract_to}\")\n",
        "\n",
        "# Create extraction directory\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# Check what files are in Google Drive\n",
        "print(f\"\\nüîç Checking files in {source_dir}...\")\n",
        "if os.path.exists(source_dir):\n",
        "    files_in_drive = os.listdir(source_dir)\n",
        "    print(f\"‚úÖ Found {len(files_in_drive)} items\")\n",
        "\n",
        "    # Show all items\n",
        "    print(\"\\nüìÇ Items in Drive:\")\n",
        "    for item in files_in_drive:\n",
        "        item_path = os.path.join(source_dir, item)\n",
        "        if os.path.isfile(item_path):\n",
        "            size_mb = os.path.getsize(item_path) / (1024*1024)\n",
        "            print(f\"   üìÑ {item} ({size_mb:.1f} MB)\")\n",
        "        else:\n",
        "            print(f\"   üìÅ {item}/\")\n",
        "\n",
        "    # Find tar.gz files\n",
        "    tar_files = [f for f in files_in_drive if f.endswith('.tar.gz') or f.endswith('.tgz')]\n",
        "\n",
        "    if tar_files:\n",
        "        print(f\"\\nüì¶ Found {len(tar_files)} TAR.GZ file(s)\")\n",
        "\n",
        "        # Ask which file to extract (or extract F30 by default)\n",
        "        print(\"\\nüí° Extracting embryo_dataset_F-45.tar.gz...\")\n",
        "        target_file = \"embryo_dataset_F-45.tar.gz\"\n",
        "\n",
        "        if target_file in tar_files:\n",
        "            tar_path = os.path.join(source_dir, target_file)\n",
        "            print(f\"\\nüì• Extracting: {target_file}\")\n",
        "            print(f\"   Size: {os.path.getsize(tar_path) / (1024*1024*1024):.1f} GB\")\n",
        "            print(\"   ‚è≥ This will take 5-15 minutes...\")\n",
        "\n",
        "            try:\n",
        "                with tarfile.open(tar_path, 'r:gz') as tar_ref:\n",
        "                    # Extract all files\n",
        "                    tar_ref.extractall(extract_to)\n",
        "                    print(f\"   ‚úÖ Extracted successfully!\")\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå Error: {str(e)}\")\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è {target_file} not found in Drive!\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"‚úÖ EXTRACTION COMPLETE!\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Show extracted structure\n",
        "        print(\"\\nüìÇ Extracted structure:\")\n",
        "        !ls -lh {extract_to}\n",
        "\n",
        "        # Count images\n",
        "        print(\"\\nüîç Counting images...\")\n",
        "        image_count = 0\n",
        "        for root, dirs, files in os.walk(extract_to):\n",
        "            image_count += len([f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))])\n",
        "        print(f\"‚úÖ Found {image_count} images!\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è No TAR.GZ files found!\")\n",
        "        print(\"üí° Looking for images directly in Drive...\")\n",
        "\n",
        "        # Check if images exist directly in Drive\n",
        "        image_files = [f for f in files_in_drive if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
        "        if image_files:\n",
        "            print(f\"‚úÖ Found {len(image_files)} images directly in Drive\")\n",
        "            print(\"üí° Using images from Google Drive directly (no extraction needed)\")\n",
        "        else:\n",
        "            print(\"‚ùå No images or TAR.GZ files found!\")\n",
        "            print(\"üìã Available files:\")\n",
        "            for f in files_in_drive:\n",
        "                print(f\"   - {f}\")\n",
        "else:\n",
        "    print(f\"‚ùå Directory not found: {source_dir}\")\n",
        "    print(\"\\nüí° Update the 'source_dir' path to match your Google Drive location\")\n",
        "    print(\"   Common locations:\")\n",
        "    print(\"   - /content/drive/MyDrive/gfgIVF\")\n",
        "    print(\"   - /content/drive/MyDrive/EmbryoProject\")\n",
        "    print(\"   - /content/drive/MyDrive/[your-folder-name]\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 3Ô∏è‚É£ FIND ALL IMAGES\n",
        "# ============================================================\n",
        "# Find all image files\n",
        "import glob\n",
        "\n",
        "print(\"üîç Searching for image files...\")\n",
        "\n",
        "# Search for image formats in multiple locations\n",
        "image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp']\n",
        "image_files = []\n",
        "\n",
        "# Try multiple locations (prioritize local, fallback to Drive)\n",
        "search_paths = [\n",
        "    # '/content/embryo_data',                                           # Local Colab storage (fastest)\n",
        "    '/content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45',  # F45 dataset in Drive\n",
        "    # '/content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F30',  # F30 dataset in Drive\n",
        "    # '/content/drive/MyDrive/gfgIVF/embryo_data',                     # All datasets in Drive\n",
        "]\n",
        "\n",
        "found_location = None\n",
        "for search_path in search_paths:\n",
        "    if os.path.exists(search_path):\n",
        "        found_location = search_path\n",
        "        storage_type = \"local Colab storage\" if \"drive\" not in search_path else \"Google Drive\"\n",
        "        print(f\"\\nüìÇ Searching in: {search_path}\")\n",
        "        print(f\"   Storage: {storage_type}\")\n",
        "        print(f\"   ‚è≥ Please wait... (Google Drive searches can take 5-10 minutes)\")\n",
        "\n",
        "        for ext in image_extensions:\n",
        "            print(f\"\\n   Searching for {ext} files...\")\n",
        "            found = glob.glob(f'{search_path}/**/{ext}', recursive=True)\n",
        "            if found:\n",
        "                image_files.extend(found)\n",
        "                print(f\"   ‚úÖ Found {len(found)} {ext} files\")\n",
        "\n",
        "        if len(image_files) > 0:\n",
        "            print(f\"\\n   üéâ Successfully found images in {storage_type}!\")\n",
        "            break  # Stop searching once we find images\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è No images found in this location, checking next...\")\n",
        "\n",
        "if found_location is None:\n",
        "    print(\"\\n‚ùå Dataset not found in any location!\")\n",
        "    print(\"\\nüí° Please check:\")\n",
        "    print(\"   1. Mount Google Drive (Cell 4)\")\n",
        "    print(\"   2. Verify data location in your Drive\")\n",
        "    print(\"   3. Update search_paths in this cell if needed\")\n",
        "\n",
        "# Remove duplicates\n",
        "image_files = list(set(image_files))\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"‚úÖ FOUND {len(image_files)} TOTAL IMAGE FILES\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "if len(image_files) > 0:\n",
        "    print(f\"\\nüì∏ Sample images (first 10):\")\n",
        "    for img in image_files[:10]:\n",
        "        print(f\"   {img}\")\n",
        "\n",
        "    if len(image_files) > 10:\n",
        "        print(f\"   ... and {len(image_files) - 10} more images\")\n",
        "\n",
        "    # Check directory structure to understand labeling\n",
        "    print(f\"\\nüìä Analyzing directory structure for labels...\")\n",
        "    dirs_with_images = set()\n",
        "    for img_path in image_files[:100]:  # Sample first 100\n",
        "        parent_dir = os.path.basename(os.path.dirname(img_path))\n",
        "        dirs_with_images.add(parent_dir)\n",
        "\n",
        "    print(f\"   Images found in these folders: {sorted(dirs_with_images)}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No image files found!\")\n",
        "    print(\"\\nüí° Checking directory contents...\")\n",
        "    for path in search_paths:\n",
        "        if os.path.exists(path):\n",
        "            print(f\"\\nüìÇ Contents of {path}:\")\n",
        "            !ls -lh {path} | head -20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWVBo06XJp3B",
        "outputId": "007615e5-6bd5-4a47-91bc-236cb187e531"
      },
      "id": "eWVBo06XJp3B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Searching for image files...\n",
            "\n",
            "üìÇ Searching in: /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45\n",
            "   Storage: Google Drive\n",
            "   ‚è≥ Please wait... (Google Drive searches can take 5-10 minutes)\n",
            "\n",
            "   Searching for *.png files...\n",
            "\n",
            "   Searching for *.jpg files...\n",
            "\n",
            "   Searching for *.jpeg files...\n",
            "   ‚úÖ Found 211248 *.jpeg files\n",
            "\n",
            "   Searching for *.bmp files...\n",
            "\n",
            "   üéâ Successfully found images in Google Drive!\n",
            "\n",
            "============================================================\n",
            "‚úÖ FOUND 211248 TOTAL IMAGE FILES\n",
            "============================================================\n",
            "\n",
            "üì∏ Sample images (first 10):\n",
            "   /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45/PA145-1/D2013.02.11_S0732_I132_WELL1_RUN275.jpeg\n",
            "   /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45/DS61-1/D2012.01.27_S0364_I132_WELL1_RUN271.jpeg\n",
            "   /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45/CA390-6/D2017.04.15_S1905_I132_WELL6_RUN410.jpeg\n",
            "   /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45/JL073-6/D2016.01.29_S0303_I647_WELL6_RUN327.jpeg\n",
            "   /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45/KA474-5/D2014.05.29_S1113_I132_WELL5_RUN43.jpeg\n",
            "   /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45/MM445-2-9/D2016.05.13_S1650_I132_WELL9_RUN75.jpeg\n",
            "   /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45/CAV074-1/D2016.01.29_S1566_I132_WELL1_RUN554.jpeg\n",
            "   /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45/GC381-10/D2014.04.30_S1086_I132_WELL10_RUN274.jpeg\n",
            "   /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45/PMDPI029-1-10/D2016.02.22_S1584_I132_WELL10_RUN19.jpeg\n",
            "   /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45/DML373-2/D2014.04.29_S1085_I132_WELL2_RUN382.jpeg\n",
            "   ... and 211238 more images\n",
            "\n",
            "üìä Analyzing directory structure for labels...\n",
            "   Images found in these folders: ['ALR493-10', 'ALR493-6', 'AM685-3', 'AM716-1', 'BC782-2', 'BJ492-11', 'BJ497-7', 'BL526-1', 'BM007-9', 'BMS819-7', 'BS1086-1', 'BS777-8', 'BY829-3', 'CA390-6', 'CAV074-1', 'CAV074-6', 'CM010-10', 'DC307-1', 'DE069-10', 'DL61-2', 'DML373-2', 'DN340-2', 'DS61-1', 'DSM138-5', 'DV728-7', 'DY236-4', 'EA32-6', 'EH309-8', 'FC048-6', 'FN852-1', 'GA1087-6', 'GA911-3', 'GC381-10', 'GE1055-6', 'GE218-3', 'GE294-4', 'GF1042-2-6', 'GF667-1-1', 'GJ316-1', 'GM456-3', 'GS415-5', 'GS611-3', 'HH569-2', 'HH569-4', 'HL369-6', 'JL073-6', 'JM1088-1', 'KA474-5', 'LBE649-3', 'LC47-8', 'LP284-3', 'LS058-7', 'LS058-8', 'LT634-4', 'LTE064-8', 'ME577-7', 'MM445-2-2', 'MM445-2-9', 'MM834-5', 'MS511-2-3', 'MS624-4', 'MS624-6', 'MS624-8', 'MV930-2', 'PA145-1', 'PH394-2', 'PMDPI029-1-10', 'PMDPI029-1-2', 'PMDPI029-1-8', 'QC211-2', 'RBC697-1', 'RI273-6', 'RI382-2', 'RL948-2', 'RM184-1', 'RM29-5', 'SLM044-1-1', 'SS684-8', 'UL050-_9', 'VA197-2', 'VM195-6', 'VM569-7', 'VS510-2', 'ZS435-5', 'ZS435-6']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load annotations (embryo labels)\n",
        "print(\"üìã Loading embryo annotations...\")\n",
        "\n",
        "# Check what's in the annotations directory\n",
        "annotations_dir = \"/content/drive/MyDrive/gfgIVF/embryo_dataset_annotations/embryo_dataset_annotations\"\n",
        "\n",
        "if os.path.exists(annotations_dir):\n",
        "    print(f\"‚úÖ Found annotations directory: {annotations_dir}\")\n",
        "\n",
        "    # List files in annotations directory\n",
        "    print(\"\\nüìÇ Files in annotations directory:\")\n",
        "    !ls -lh {annotations_dir}\n",
        "\n",
        "    # Try to find CSV or text files\n",
        "    import glob\n",
        "    csv_files = glob.glob(f'{annotations_dir}/*.csv')\n",
        "    txt_files = glob.glob(f'{annotations_dir}/*.txt')\n",
        "    json_files = glob.glob(f'{annotations_dir}/*.json')\n",
        "\n",
        "    print(f\"\\nüîç Found:\")\n",
        "    print(f\"   CSV files: {len(csv_files)}\")\n",
        "    print(f\"   TXT files: {len(txt_files)}\")\n",
        "    print(f\"   JSON files: {len(json_files)}\")\n",
        "\n",
        "    # Try to load the first available file\n",
        "    if csv_files:\n",
        "        annotations_file = csv_files[0]\n",
        "        print(f\"\\nüìÑ Loading: {os.path.basename(annotations_file)}\")\n",
        "\n",
        "        # Try different separators\n",
        "        try:\n",
        "            df_labels = pd.read_csv(annotations_file)\n",
        "        except:\n",
        "            try:\n",
        "                df_labels = pd.read_csv(annotations_file, sep='\\t')\n",
        "            except:\n",
        "                df_labels = pd.read_csv(annotations_file, sep=';')\n",
        "\n",
        "        print(f\"‚úÖ Loaded {len(df_labels)} annotations\")\n",
        "        print(f\"\\nüìä Columns: {list(df_labels.columns)}\")\n",
        "        print(f\"\\nüëÄ First 10 rows:\")\n",
        "        print(df_labels.head(10))\n",
        "\n",
        "        # Show unique labels\n",
        "        print(f\"\\nüè∑Ô∏è Checking for label columns...\")\n",
        "        for col in df_labels.columns:\n",
        "            if 'label' in col.lower() or 'class' in col.lower() or 'outcome' in col.lower() or 'quality' in col.lower():\n",
        "                print(f\"   Found: '{col}' - Unique values: {df_labels[col].unique()}\")\n",
        "\n",
        "    elif txt_files:\n",
        "        print(f\"\\nüìÑ Found TXT file: {txt_files[0]}\")\n",
        "        print(\"\\nüëÄ First 20 lines:\")\n",
        "        !head -20 {txt_files[0]}\n",
        "\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è No CSV, TXT, or JSON files found in annotations directory\")\n",
        "        print(\"Showing all files:\")\n",
        "        !ls -la {annotations_dir}\n",
        "\n",
        "else:\n",
        "    print(f\"‚ùå Annotations directory not found: {annotations_dir}\")\n",
        "    print(\"\\nüí° Looking for annotations tar.gz file to extract...\")\n",
        "\n",
        "    tar_file = \"/content/drive/MyDrive/gfgIVF/embryo_dataset_annotations.tar.gz\"\n",
        "    if os.path.exists(tar_file):\n",
        "        print(f\"‚úÖ Found: {tar_file}\")\n",
        "        print(\"Extracting...\")\n",
        "\n",
        "        import tarfile\n",
        "        extract_to = \"/content/drive/MyDrive/gfgIVF\"\n",
        "\n",
        "        with tarfile.open(tar_file, 'r:gz') as tar_ref:\n",
        "            tar_ref.extractall(extract_to)\n",
        "\n",
        "        print(\"‚úÖ Extracted! Re-run this cell to load annotations.\")\n",
        "    else:\n",
        "        print(\"‚ùå Annotations file not found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3XDIzLiZKdhS",
        "outputId": "2d72e32f-b005-41aa-eb1d-29535c5dc9e9"
      },
      "id": "3XDIzLiZKdhS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Loading embryo annotations...\n",
            "‚úÖ Found annotations directory: /content/drive/MyDrive/gfgIVF/embryo_dataset_annotations/embryo_dataset_annotations\n",
            "\n",
            "üìÇ Files in annotations directory:\n",
            "total 352K\n",
            "-rw------- 1 root root 108 Dec  9  2021 AA83-7_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 AAL839-6_phases.csv\n",
            "-rw------- 1 root root  80 Dec  9  2021 AB028-6_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 AB91-1_phases.csv\n",
            "-rw------- 1 root root  98 Dec  9  2021 AC264-1_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 ADM715-1-2_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 AG274-2_phases.csv\n",
            "-rw------- 1 root root 127 Dec  9  2021 AG782-6_phases.csv\n",
            "-rw------- 1 root root  90 Dec  9  2021 AG782-8_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 AH988-4_phases.csv\n",
            "-rw------- 1 root root 113 Dec  9  2021 AHS115-5_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 AHS599-4_phases.csv\n",
            "-rw------- 1 root root 135 Dec  9  2021 AK383-1_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 AL702-9_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 AL884-2_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 ALR493-10_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 ALR493-6_phases.csv\n",
            "-rw------- 1 root root  97 Dec  9  2021 AM33-2_phases.csv\n",
            "-rw------- 1 root root 103 Dec  9  2021 AM365-7_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 AM685-3_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 AM716-1_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 AM716-7_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 AM918-2-5_phases.csv\n",
            "-rw------- 1 root root 109 Dec  9  2021 AMT360-1-9_phases.csv\n",
            "-rw------- 1 root root 141 Dec  9  2021 AS1015-2_phases.csv\n",
            "-rw------- 1 root root 124 Dec  9  2021 AS556-3_phases.csv\n",
            "-rw------- 1 root root  76 Dec  9  2021 AS563-1_phases.csv\n",
            "-rw------- 1 root root 110 Dec  9  2021 AS662-2_phases.csv\n",
            "-rw------- 1 root root  86 Dec  9  2021 AS71-3_phases.csv\n",
            "-rw------- 1 root root 125 Dec  9  2021 BA1195-9_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 BA25-7_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 BA258-6_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 BA518-7_phases.csv\n",
            "-rw------- 1 root root 138 Dec  9  2021 BA560-1_phases.csv\n",
            "-rw------- 1 root root 135 Dec  9  2021 BA560-2_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 BA782-2_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 BA958-2_phases.csv\n",
            "-rw------- 1 root root  98 Dec  9  2021 BC167-4_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 BC254-1_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 BC254-5_phases.csv\n",
            "-rw------- 1 root root 126 Dec  9  2021 BC277-10_phases.csv\n",
            "-rw------- 1 root root 112 Dec  9  2021 BC277-9_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 BC396-1_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 BC396-2_phases.csv\n",
            "-rw------- 1 root root 168 Dec  9  2021 BC518-6_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 BC750-7_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 BC782-2_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 BC973-4_phases.csv\n",
            "-rw------- 1 root root 104 Dec  9  2021 BE327-2_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 BE340-9_phases.csv\n",
            "-rw------- 1 root root 133 Dec  9  2021 BE413-3_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 BE645-10_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 BE645-3_phases.csv\n",
            "-rw------- 1 root root 125 Dec  9  2021 BE645-7_phases.csv\n",
            "-rw------- 1 root root  97 Dec  9  2021 BE735-2_phases.csv\n",
            "-rw------- 1 root root 168 Dec  9  2021 BF924-3_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 BG201-1_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 BG723-5_phases.csv\n",
            "-rw------- 1 root root 124 Dec  9  2021 BH034-4_phases.csv\n",
            "-rw------- 1 root root 125 Dec  9  2021 BI104-3_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 BI224-2_phases.csv\n",
            "-rw------- 1 root root 133 Dec  9  2021 BJ3371-10_phases.csv\n",
            "-rw------- 1 root root  99 Dec  9  2021 BJ3371-9_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 BJ492-11_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 BJ492-8_phases.csv\n",
            "-rw------- 1 root root  72 Dec  9  2021 BJ497-7_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 BK428-2_phases.csv\n",
            "-rw------- 1 root root 154 Dec  9  2021 BL042-8_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 BL285-1-3_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 BL366-6_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 BL418-7_phases.csv\n",
            "-rw------- 1 root root 111 Dec  9  2021 BL526-1_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 BL526-4_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 BL526-5_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 BM007-9_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 BM016-2_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 BM016-5_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 BM076-4_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 BM201-1_phases.csv\n",
            "-rw------- 1 root root 102 Dec  9  2021 BM209-8_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 BM256-1_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 BM256-4_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 BM352-6_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 BM414-3_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 BM655-10_phases.csv\n",
            "-rw------- 1 root root 128 Dec  9  2021 BM968-3_phases.csv\n",
            "-rw------- 1 root root 108 Dec  9  2021 BM984-2_phases.csv\n",
            "-rw------- 1 root root 133 Dec  9  2021 BMH857-2_phases.csv\n",
            "-rw------- 1 root root  69 Dec  9  2021 BMS288-1_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 BMS819-7_phases.csv\n",
            "-rw------- 1 root root  91 Dec  9  2021 BN1010-5_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 BN356-3_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 BN356-6_phases.csv\n",
            "-rw------- 1 root root 125 Dec  9  2021 BO613-7_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 BR953-7_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 BS1033-2_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 BS1086-1_phases.csv\n",
            "-rw------- 1 root root  97 Dec  9  2021 BS294-7_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 BS495-9_phases.csv\n",
            "-rw------- 1 root root  80 Dec  9  2021 BS544-1_phases.csv\n",
            "-rw------- 1 root root  98 Dec  9  2021 BS596-5_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 BS648-2-4_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 BS648-7_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 BS777-8_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 BS836-11_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 BS918-6_phases.csv\n",
            "-rw------- 1 root root  73 Dec  9  2021 BV646-6_phases.csv\n",
            "-rw------- 1 root root 124 Dec  9  2021 BY829-1_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 BY829-3_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 CA063-10_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 CA063-6_phases.csv\n",
            "-rw------- 1 root root 112 Dec  9  2021 CA364-7_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 CA390-2_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 CA390-6_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 CA658-12_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 CA658-6_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 CA704-2_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 CAV074-1_phases.csv\n",
            "-rw------- 1 root root 126 Dec  9  2021 CAV074-3_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 CAV074-4_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 CAV074-5_phases.csv\n",
            "-rw------- 1 root root 125 Dec  9  2021 CAV074-6_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 CAV074-8_phases.csv\n",
            "-rw------- 1 root root  69 Dec  9  2021 CAV074-9_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 CC007-2_phases.csv\n",
            "-rw------- 1 root root 117 Dec  9  2021 CC336-9_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 CC455-3_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 CC563-5_phases.csv\n",
            "-rw------- 1 root root 142 Dec  9  2021 CC751-4_phases.csv\n",
            "-rw------- 1 root root 142 Dec  9  2021 CC938-4_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 CC966-1_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 CE417-1_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 CE417-3_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 CE417-6_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 CE525-2_phases.csv\n",
            "-rw------- 1 root root 120 Dec  9  2021 CE604-1_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 CE712-2_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 CF946-6_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 CJ261-10_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 CJ261-6_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 CJ528-1_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 CK601-2_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 CK601-4_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 CL783-2_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 CM010-10_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 CM010-7_phases.csv\n",
            "-rw------- 1 root root  76 Dec  9  2021 CM1073-4_phases.csv\n",
            "-rw------- 1 root root 141 Dec  9  2021 CM146-1_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 CM627-1_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 CM627-3_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 CM627-8_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 CM641-1-8_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 CM782-8_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 CM892-5_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 CN473-1_phases.csv\n",
            "-rw------- 1 root root 135 Dec  9  2021 CN606-5_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 CO119-8_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 CS552-2_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 CS552-4_phases.csv\n",
            "-rw------- 1 root root 114 Dec  9  2021 CV306-2_phases.csv\n",
            "-rw------- 1 root root 154 Dec  9  2021 CZ594-1_phases.csv\n",
            "-rw------- 1 root root 154 Dec  9  2021 CZ594-5_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 DA1054-5_phases.csv\n",
            "-rw------- 1 root root 125 Dec  9  2021 DA309-5_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 DA684-4_phases.csv\n",
            "-rw------- 1 root root  67 Dec  9  2021 DA769-1_phases.csv\n",
            "-rw------- 1 root root 109 Dec  9  2021 DA781-4_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 DA925-6_phases.csv\n",
            "-rw------- 1 root root  87 Dec  9  2021 DAS678-1_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 DAS706-3_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 DC307-1_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 DC307-2_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 DC307-7_phases.csv\n",
            "-rw------- 1 root root  97 Dec  9  2021 DC932-2_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 DE069-10_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 DE069-2_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 DE069-3_phases.csv\n",
            "-rw------- 1 root root 170 Dec  9  2021 DE069-7_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 DE604-3_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 DE842-3_phases.csv\n",
            "-rw------- 1 root root  80 Dec  9  2021 DG487-4_phases.csv\n",
            "-rw------- 1 root root  81 Dec  9  2021 DH1012-1_phases.csv\n",
            "-rw------- 1 root root 114 Dec  9  2021 DHDPI042-3_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 DHDPI042-6_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 DHDPI042-7_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 DHDPI042-8_phases.csv\n",
            "-rw------- 1 root root 109 Dec  9  2021 DI358-3_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 DJC641-4_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 DL020-3_phases.csv\n",
            "-rw------- 1 root root  67 Dec  9  2021 DL266-4_phases.csv\n",
            "-rw------- 1 root root  80 Dec  9  2021 DL61-2_phases.csv\n",
            "-rw------- 1 root root 101 Dec  9  2021 DL617-6_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 DM1046-12_phases.csv\n",
            "-rw------- 1 root root  81 Dec  9  2021 DM1114-6_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 DM235-3_phases.csv\n",
            "-rw------- 1 root root  86 Dec  9  2021 DML271-2_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 DML373-2_phases.csv\n",
            "-rw------- 1 root root 124 Dec  9  2021 DN340-2_phases.csv\n",
            "-rw------- 1 root root 168 Dec  9  2021 DN376-8_phases.csv\n",
            "-rw------- 1 root root  62 Dec  9  2021 DN881-6_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 DRL1048-1_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 DS17-2_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 DS61-1_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 DS666-9_phases.csv\n",
            "-rw------- 1 root root  89 Dec  9  2021 DS947-2_phases.csv\n",
            "-rw------- 1 root root  78 Dec  9  2021 DSE41-2_phases.csv\n",
            "-rw------- 1 root root 125 Dec  9  2021 DSM138-5_phases.csv\n",
            "-rw------- 1 root root 110 Dec  9  2021 DT336-1_phases.csv\n",
            "-rw------- 1 root root  98 Dec  9  2021 DT336-2_phases.csv\n",
            "-rw------- 1 root root  54 Dec  9  2021 DV116-3_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 DV210-4_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 DV210-8_phases.csv\n",
            "-rw------- 1 root root  69 Dec  9  2021 DV305-3_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 DV728-6_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 DV728-7_phases.csv\n",
            "-rw------- 1 root root  88 Dec  9  2021 DY236-4_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 EA32-6_phases.csv\n",
            "-rw------- 1 root root 111 Dec  9  2021 EC234-5_phases.csv\n",
            "-rw------- 1 root root 106 Dec  9  2021 EE656-3_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 EH309-8_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 EH315-3_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 EH315-8_phases.csv\n",
            "-rw------- 1 root root  59 Dec  9  2021 EH512-10_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 EJ393-3_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 FA344-5_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 FA662-6_phases.csv\n",
            "-rw------- 1 root root  90 Dec  9  2021 FC048-6_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 FC1164-11_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 FD156-4_phases.csv\n",
            "-rw------- 1 root root  72 Dec  9  2021 FE14-020_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 FF717-4_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 FH658-4_phases.csv\n",
            "-rw------- 1 root root 103 Dec  9  2021 FM1017-5_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 FM162-6_phases.csv\n",
            "-rw------- 1 root root  66 Dec  9  2021 FM864-7_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 FN852-1_phases.csv\n",
            "-rw------- 1 root root  61 Dec  9  2021 FS987-5_phases.csv\n",
            "-rw------- 1 root root 105 Dec  9  2021 FV709-11_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 GA1087-6_phases.csv\n",
            "-rw------- 1 root root 112 Dec  9  2021 GA122-8_phases.csv\n",
            "-rw------- 1 root root  79 Dec  9  2021 GA365-1_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 GA425-1_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 GA664-1_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 GA664-3_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 GA664-4_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 GA664-8_phases.csv\n",
            "-rw------- 1 root root 120 Dec  9  2021 GA703-2-7_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 GA800-4_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 GA817-1-8_phases.csv\n",
            "-rw------- 1 root root  87 Dec  9  2021 GA911-3_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 GA982-7_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 GC340-10_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 GC340-1_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 GC340-3_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 GC381-10_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 GC658-3_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 GC658-9_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 GC702-6_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 GC836-1_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 GC836-4_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 GC851-5_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 GD391-8_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 GD391-9_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 GE1055-6_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 GE218-3_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 GE294-4_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 GE663-5_phases.csv\n",
            "-rw------- 1 root root  86 Dec  9  2021 GE843-2_phases.csv\n",
            "-rw------- 1 root root  91 Dec  9  2021 GF083-5_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 GF1042-1-3_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 GF1042-2-6_phases.csv\n",
            "-rw------- 1 root root 110 Dec  9  2021 GF667-1-1_phases.csv\n",
            "-rw------- 1 root root  76 Dec  9  2021 GF667-2-6_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 GF976-4_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 GG677-5_phases.csv\n",
            "-rw------- 1 root root 133 Dec  9  2021 GJ165-5_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 GJ191-1_phases.csv\n",
            "-rw------- 1 root root  90 Dec  9  2021 GJ285-1_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 GJ316-1_phases.csv\n",
            "-rw------- 1 root root 106 Dec  9  2021 GM213-2_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 GM293-2_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 GM293-3_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 GM456-3_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 GM537-7_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 GM858-1-3_phases.csv\n",
            "-rw------- 1 root root 125 Dec  9  2021 GM858-2-6_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 GML002-7_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 GNB477-5_phases.csv\n",
            "-rw------- 1 root root 141 Dec  9  2021 GRSO424-8_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 GS205-2_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 GS205-6_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 GS220-2_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 GS334-6_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 GS349-4_phases.csv\n",
            "-rw------- 1 root root 126 Dec  9  2021 GS400-7_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 GS415-5_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 GS430-1_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 GS430-2_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 GS430-9_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 GS490-2_phases.csv\n",
            "-rw------- 1 root root 170 Dec  9  2021 GS490-4_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 GS490-_6_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 GS490-7_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 GS611-3_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 GS611-4_phases.csv\n",
            "-rw------- 1 root root 125 Dec  9  2021 GS753-8_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 GS811-3_phases.csv\n",
            "-rw------- 1 root root 154 Dec  9  2021 GS826-2_phases.csv\n",
            "-rw------- 1 root root 103 Dec  9  2021 GS955-7_phases.csv\n",
            "-rw------- 1 root root 103 Dec  9  2021 GS980-2_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 GSS052-2_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 GSS052-6_phases.csv\n",
            "-rw------- 1 root root 131 Dec  9  2021 GT353-3_phases.csv\n",
            "-rw------- 1 root root 153 Dec  9  2021 GUDPI077-8_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 HA1040-4_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 HC459-6_phases.csv\n",
            "-rw------- 1 root root 109 Dec  9  2021 HC724-5_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 HE377-4_phases.csv\n",
            "-rw------- 1 root root 120 Dec  9  2021 HE444-3_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 HE444-4_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 HE469-5_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 HF71-3_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 HH569-2_phases.csv\n",
            "-rw------- 1 root root 142 Dec  9  2021 HH569-4_phases.csv\n",
            "-rw------- 1 root root  83 Dec  9  2021 HL369-6_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 HM214-2-9_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 HM69-4_phases.csv\n",
            "-rw------- 1 root root  84 Dec  9  2021 HS15-11_phases.csv\n",
            "-rw------- 1 root root 135 Dec  9  2021 HS160-4_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 HS893-8_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 HV298-8_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 IZ1001-1_phases.csv\n",
            "-rw------- 1 root root  92 Dec  9  2021 JC858-4_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 JE021-4_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 JL073-6_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 JM1088-1_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 JS292-7_phases.csv\n",
            "-rw------- 1 root root 112 Dec  9  2021 JS292-8_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 JV227-2_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 JV227-5_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 KA474-5_phases.csv\n",
            "-rw------- 1 root root 135 Dec  9  2021 KD774-4_phases.csv\n",
            "-rw------- 1 root root 105 Dec  9  2021 KF460-11_phases.csv\n",
            "-rw------- 1 root root 117 Dec  9  2021 KF460-3_phases.csv\n",
            "-rw------- 1 root root 130 Dec  9  2021 KF460-4_phases.csv\n",
            "-rw------- 1 root root 141 Dec  9  2021 KF460-5_phases.csv\n",
            "-rw------- 1 root root 130 Dec  9  2021 KF460-7_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 KJ1077-3_phases.csv\n",
            "-rw------- 1 root root  87 Dec  9  2021 KJ426-9_phases.csv\n",
            "-rw------- 1 root root 142 Dec  9  2021 KT573-4_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 LA1012-5_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 LA1071-6_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 LA367-4_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 LA386-4_phases.csv\n",
            "-rw------- 1 root root 103 Dec  9  2021 LA467-2_phases.csv\n",
            "-rw------- 1 root root  86 Dec  9  2021 LA733-3_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 LA825-5_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 LAC959-6_phases.csv\n",
            "-rw------- 1 root root 100 Dec  9  2021 LBE649-3_phases.csv\n",
            "-rw------- 1 root root  95 Dec  9  2021 LBE857-1_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 LBM519-10_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 LBM519-1_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 LBM659-6_phases.csv\n",
            "-rw------- 1 root root  76 Dec  9  2021 LBR602-1_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 LBS371-1-8_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 LC161-1-4_phases.csv\n",
            "-rw------- 1 root root 124 Dec  9  2021 LC161-2-5_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 LC47-8_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 LC498-2_phases.csv\n",
            "-rw------- 1 root root 118 Dec  9  2021 LC648-1_phases.csv\n",
            "-rw------- 1 root root 109 Dec  9  2021 LC648-2_phases.csv\n",
            "-rw------- 1 root root  76 Dec  9  2021 LC765-2_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 LCF544-2_phases.csv\n",
            "-rw------- 1 root root 102 Dec  9  2021 LCF979-1_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 LD400-1_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 LD400-6_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 LE679-8_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 LEG557-3_phases.csv\n",
            "-rw------- 1 root root  81 Dec  9  2021 LFA766-1_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 LG168-3_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 LGA21-6_phases.csv\n",
            "-rw------- 1 root root  97 Dec  9  2021 LGA881-1-2_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 LGA881-2-5_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 LH1169-8_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 LHV745-7_phases.csv\n",
            "-rw------- 1 root root 118 Dec  9  2021 LK523-2_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 LK584-2_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 LK584-3_phases.csv\n",
            "-rw------- 1 root root 111 Dec  9  2021 LL1196-5_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 LL854-1_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 LLA399-2_phases.csv\n",
            "-rw------- 1 root root 120 Dec  9  2021 LLN757-6_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 LLN873-1_phases.csv\n",
            "-rw------- 1 root root 154 Dec  9  2021 LM184-3_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 LM184-4_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 LM335-7_phases.csv\n",
            "-rw------- 1 root root  65 Dec  9  2021 LM844-1_phases.csv\n",
            "-rw------- 1 root root  76 Dec  9  2021 LM985-4_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 LMMG218-1-10_phases.csv\n",
            "-rw------- 1 root root  97 Dec  9  2021 LN233-3_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 LNA592-8_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 LNA592-9_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 LP181-1_phases.csv\n",
            "-rw------- 1 root root  77 Dec  9  2021 LP284-3_phases.csv\n",
            "-rw------- 1 root root 154 Dec  9  2021 LS058-7_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 LS058-8_phases.csv\n",
            "-rw------- 1 root root 102 Dec  9  2021 LS1035-1_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 LS1045-4_phases.csv\n",
            "-rw------- 1 root root 179 Dec  9  2021 LS123-3_phases.csv\n",
            "-rw------- 1 root root 141 Dec  9  2021 LS359-1-7_phases.csv\n",
            "-rw------- 1 root root  98 Dec  9  2021 LS366-1_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 LS93-8_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 LSD500-3_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 LSD500-6_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 LT1112-5_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 LT634-4_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 LTA908-2_phases.csv\n",
            "-rw------- 1 root root 135 Dec  9  2021 LTE064-1_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 LTE064-5_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 LTE064-8_phases.csv\n",
            "-rw------- 1 root root 112 Dec  9  2021 LV366-6_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 LV488-7_phases.csv\n",
            "-rw------- 1 root root 170 Dec  9  2021 LV613-2_phases.csv\n",
            "-rw------- 1 root root 127 Dec  9  2021 LV683-2-3_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 LV683-2-8_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 LV723-1_phases.csv\n",
            "-rw------- 1 root root 131 Dec  9  2021 LV723-9_phases.csv\n",
            "-rw------- 1 root root 109 Dec  9  2021 LYI1079-2_phases.csv\n",
            "-rw------- 1 root root 105 Dec  9  2021 LZ865-2_phases.csv\n",
            "-rw------- 1 root root  97 Dec  9  2021 MA1007-3_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 MA1059-3_phases.csv\n",
            "-rw------- 1 root root  98 Dec  9  2021 MA470-5_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 MA488-3_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 MA505-1_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 MA505-2_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 MA595-5_phases.csv\n",
            "-rw------- 1 root root 154 Dec  9  2021 MA752-1_phases.csv\n",
            "-rw------- 1 root root  99 Dec  9  2021 MA797-4_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 MA797-7_phases.csv\n",
            "-rw------- 1 root root  88 Dec  9  2021 MA8-2_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 MA885-10_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 MAS094-2_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 MAS094-5_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 MAS203-4_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 MAS203-6_phases.csv\n",
            "-rw------- 1 root root 131 Dec  9  2021 MC373-5_phases.csv\n",
            "-rw------- 1 root root  76 Dec  9  2021 MC427-1_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 MC663-7_phases.csv\n",
            "-rw------- 1 root root 110 Dec  9  2021 MC710-3_phases.csv\n",
            "-rw------- 1 root root  84 Dec  9  2021 MC833-6_phases.csv\n",
            "-rw------- 1 root root 101 Dec  9  2021 MC933-2_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 MDCH869-4_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 ME378-4_phases.csv\n",
            "-rw------- 1 root root  79 Dec  9  2021 ME540-11_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 ME540-7_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 ME577-7_phases.csv\n",
            "-rw------- 1 root root 127 Dec  9  2021 ME799-5_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 MF532-3_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 MG1147-6_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 MI820-4_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 MJ402-10_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 ML585-2_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 ML954-3_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 MM1134-3_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 MM334-5_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 MM41-7_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 MM445-2-1_phases.csv\n",
            "-rw------- 1 root root 157 Dec  9  2021 MM445-2-2_phases.csv\n",
            "-rw------- 1 root root 111 Dec  9  2021 MM445-2-9_phases.csv\n",
            "-rw------- 1 root root  91 Dec  9  2021 MM834-5_phases.csv\n",
            "-rw------- 1 root root 102 Dec  9  2021 MM84-8_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 MM897-7_phases.csv\n",
            "-rw------- 1 root root  80 Dec  9  2021 MM912-4_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 MN011-3_phases.csv\n",
            "-rw------- 1 root root  90 Dec  9  2021 MN32-6_phases.csv\n",
            "-rw------- 1 root root 135 Dec  9  2021 MP228-5_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 MRA165-6_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 MRA165-7T_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 MS1034-1_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 MS511-2-3_phases.csv\n",
            "-rw------- 1 root root  98 Dec  9  2021 MS565-10_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 MS624-4_phases.csv\n",
            "-rw------- 1 root root 138 Dec  9  2021 MS624-6_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 MS624-7_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 MS624-8_phases.csv\n",
            "-rw------- 1 root root 100 Dec  9  2021 MT351-4_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 MT520-4_phases.csv\n",
            "-rw------- 1 root root  91 Dec  9  2021 MV750-5_phases.csv\n",
            "-rw------- 1 root root  87 Dec  9  2021 MV930-2_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 NA834-7_phases.csv\n",
            "-rw------- 1 root root  91 Dec  9  2021 NC636-4_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 ND1068-3_phases.csv\n",
            "-rw------- 1 root root 110 Dec  9  2021 NE429-4_phases.csv\n",
            "-rw------- 1 root root  96 Dec  9  2021 NK206-3_phases.csv\n",
            "-rw------- 1 root root  89 Dec  9  2021 OA170-11_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 OA333-6_phases.csv\n",
            "-rw------- 1 root root  72 Dec  9  2021 OC110-5_phases.csv\n",
            "-rw------- 1 root root  87 Dec  9  2021 OF387-2_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 OF960-2_phases.csv\n",
            "-rw------- 1 root root  87 Dec  9  2021 OJ319-10_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 OJ319-2_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 OJ319-3_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 OJ319-5_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 OJ319-6_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 OJ319-7_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 OJ319-8_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 OJ319-9_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 OP517-1_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 PA1217-8_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 PA145-1_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 PA145-2_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 PA214-5_phases.csv\n",
            "-rw------- 1 root root  97 Dec  9  2021 PA276-3_phases.csv\n",
            "-rw------- 1 root root 127 Dec  9  2021 PA289-8_phases.csv\n",
            "-rw------- 1 root root  88 Dec  9  2021 PA337-4_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 PA731-2-3_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 PA745-3_phases.csv\n",
            "-rw------- 1 root root  73 Dec  9  2021 PA916-1-10_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 PAS742-3_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 PC55-2_phases.csv\n",
            "-rw------- 1 root root  87 Dec  9  2021 PC758-2_phases.csv\n",
            "-rw------- 1 root root  90 Dec  9  2021 PC809-7_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 PD496-6_phases.csv\n",
            "-rw------- 1 root root 170 Dec  9  2021 PE081-5_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 PE256-2_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 PE256-5_phases.csv\n",
            "-rw------- 1 root root 110 Dec  9  2021 PE724-1_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 PE83-6_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 PE863-4_phases.csv\n",
            "-rw------- 1 root root 127 Dec  9  2021 PE863-9_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 PG209-3_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 PH394-2_phases.csv\n",
            "-rw------- 1 root root 140 Dec  9  2021 PH664-7_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 PH783-3_phases.csv\n",
            "-rw------- 1 root root 113 Dec  9  2021 PI1004-3_phases.csv\n",
            "-rw------- 1 root root 135 Dec  9  2021 PI1027-1_phases.csv\n",
            "-rw------- 1 root root  74 Dec  9  2021 PJ533-8_phases.csv\n",
            "-rw------- 1 root root 124 Dec  9  2021 PL974-9_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 PM273-6_phases.csv\n",
            "-rw------- 1 root root 170 Dec  9  2021 PMDPI029-1-10_phases.csv\n",
            "-rw------- 1 root root  76 Dec  9  2021 PMDPI029-1-11_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 PMDPI029-1-1_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 PMDPI029-1-2_phases.csv\n",
            "-rw------- 1 root root 133 Dec  9  2021 PMDPI029-1-3_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 PMDPI029-1-5_phases.csv\n",
            "-rw------- 1 root root 168 Dec  9  2021 PMDPI029-1-6_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 PMDPI029-1-8_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 PMDPI029-1-9_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 PN110-11_phases.csv\n",
            "-rw------- 1 root root 140 Dec  9  2021 PN110-9_phases.csv\n",
            "-rw------- 1 root root  75 Dec  9  2021 PN636-1-6_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 PO13-3_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 PS148-9_phases.csv\n",
            "-rw------- 1 root root 114 Dec  9  2021 PS292-4_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 PV361-2_phases.csv\n",
            "-rw------- 1 root root  87 Dec  9  2021 QA374-7_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 QC211-2_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 QC211-6_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 QC267-7_phases.csv\n",
            "-rw------- 1 root root 131 Dec  9  2021 QC267-8_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 QC697-4_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 QD472-3_phases.csv\n",
            "-rw------- 1 root root 119 Dec  9  2021 RA361-4_phases.csv\n",
            "-rw------- 1 root root 100 Dec  9  2021 RA467-2_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 RA580-2_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 RA803-2_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 RA803-4_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 RBC697-1_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 RC1103-1_phases.csv\n",
            "-rw------- 1 root root 100 Dec  9  2021 RC54-4_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 RC545-2-5_phases.csv\n",
            "-rw------- 1 root root 125 Dec  9  2021 RC545-2-8_phases.csv\n",
            "-rw------- 1 root root 170 Dec  9  2021 RC545-2-9_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 RC755-1_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 RC755-3_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 RC755-4_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 RC755-6_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 RC755-7_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 RC755-9_phases.csv\n",
            "-rw------- 1 root root 131 Dec  9  2021 RC812-3_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 RD1142-2_phases.csv\n",
            "-rw------- 1 root root 113 Dec  9  2021 RD167-7_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 RE260-6_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 RE828-1_phases.csv\n",
            "-rw------- 1 root root 133 Dec  9  2021 RG434-_10_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 RG434-11_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 RG864-1_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 RG944-2_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 RI273-6_phases.csv\n",
            "-rw------- 1 root root 120 Dec  9  2021 RI382-2_phases.csv\n",
            "-rw------- 1 root root  87 Dec  9  2021 RK787-3_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 RL461-4_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 RL747-8_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 RL948-2_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 RLFS800-2_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 RM126-10_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 RM126-11_phases.csv\n",
            "-rw------- 1 root root  79 Dec  9  2021 RM126-1_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 RM126-2_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 RM126-4_phases.csv\n",
            "-rw------- 1 root root 102 Dec  9  2021 RM126-5_phases.csv\n",
            "-rw------- 1 root root 149 Dec  9  2021 RM126-6_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 RM126-7_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 RM126-8_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 RM126-9_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 RM184-1_phases.csv\n",
            "-rw------- 1 root root 102 Dec  9  2021 RM29-5_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 RM549-1_phases.csv\n",
            "-rw------- 1 root root 124 Dec  9  2021 RM855-3_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 RMN410-3_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 RO793-2_phases.csv\n",
            "-rw------- 1 root root 109 Dec  9  2021 RS362-4_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 RS363-7_phases.csv\n",
            "-rw------- 1 root root  79 Dec  9  2021 RS781-7_phases.csv\n",
            "-rw------- 1 root root  86 Dec  9  2021 RV146N2-6_phases.csv\n",
            "-rw------- 1 root root 115 Dec  9  2021 RV454-6_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 RV754-4_phases.csv\n",
            "-rw------- 1 root root 135 Dec  9  2021 SA288-6_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 SC385-11_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 SC385-9_phases.csv\n",
            "-rw------- 1 root root 111 Dec  9  2021 SC700-1_phases.csv\n",
            "-rw------- 1 root root 109 Dec  9  2021 SC818-2_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 SDSA208-4_phases.csv\n",
            "-rw------- 1 root root  78 Dec  9  2021 SE040-4_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 SHE580-7_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 SK308-10_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 SK308-7_phases.csv\n",
            "-rw------- 1 root root 124 Dec  9  2021 SK902-1-8_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 SK902-6_phases.csv\n",
            "-rw------- 1 root root 155 Dec  9  2021 SL313-11_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 SLM044-1-1_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 SM307-1-12_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 SM307-1-9_phases.csv\n",
            "-rw------- 1 root root 109 Dec  9  2021 SM686-7_phases.csv\n",
            "-rw------- 1 root root 135 Dec  9  2021 SN586-8_phases.csv\n",
            "-rw------- 1 root root 136 Dec  9  2021 SS527-8_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 SS684-8_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 SS722-8_phases.csv\n",
            "-rw------- 1 root root 124 Dec  9  2021 ST586-7_phases.csv\n",
            "-rw------- 1 root root  87 Dec  9  2021 TA12-1_phases.csv\n",
            "-rw------- 1 root root 171 Dec  9  2021 TA239-2_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 TA656-2_phases.csv\n",
            "-rw------- 1 root root 107 Dec  9  2021 TA757-4_phases.csv\n",
            "-rw------- 1 root root 130 Dec  9  2021 TA757-9_phases.csv\n",
            "-rw------- 1 root root  98 Dec  9  2021 TAS1069-2_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 TC1047-2_phases.csv\n",
            "-rw------- 1 root root 114 Dec  9  2021 TD958-2-1_phases.csv\n",
            "-rw------- 1 root root 124 Dec  9  2021 TH481-5_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 TJ297-4_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 TJ899-2_phases.csv\n",
            "-rw------- 1 root root 101 Dec  9  2021 TK319-10_phases.csv\n",
            "-rw------- 1 root root 123 Dec  9  2021 TL179-5_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 TL475-7_phases.csv\n",
            "-rw------- 1 root root  77 Dec  9  2021 TM272-9_phases.csv\n",
            "-rw------- 1 root root 121 Dec  9  2021 TM294-2_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 TM312-2_phases.csv\n",
            "-rw------- 1 root root  81 Dec  9  2021 TM312-6_phases.csv\n",
            "-rw------- 1 root root 120 Dec  9  2021 TM428-3_phases.csv\n",
            "-rw------- 1 root root 147 Dec  9  2021 TM981-1_phases.csv\n",
            "-rw------- 1 root root 143 Dec  9  2021 TN359-10_phases.csv\n",
            "-rw------- 1 root root 148 Dec  9  2021 TN359-9_phases.csv\n",
            "-rw------- 1 root root 122 Dec  9  2021 TN611-7_phases.csv\n",
            "-rw------- 1 root root  91 Dec  9  2021 TN807-3_phases.csv\n",
            "-rw------- 1 root root  62 Dec  9  2021 TN888-3_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 TT615-1-8_phases.csv\n",
            "-rw------- 1 root root 126 Dec  9  2021 TV1166-4_phases.csv\n",
            "-rw------- 1 root root 103 Dec  9  2021 TV654-4_phases.csv\n",
            "-rw------- 1 root root 144 Dec  9  2021 UL050-_10_phases.csv\n",
            "-rw------- 1 root root 132 Dec  9  2021 UL050-_9_phases.csv\n",
            "-rw------- 1 root root 154 Dec  9  2021 VA197-2_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 VA197-5_phases.csv\n",
            "-rw------- 1 root root 109 Dec  9  2021 VA225-6_phases.csv\n",
            "-rw------- 1 root root 159 Dec  9  2021 VA95-1_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 VC104-2_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 VC581-10_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 VC581-11_phases.csv\n",
            "-rw------- 1 root root 168 Dec  9  2021 VC581-12_phases.csv\n",
            "-rw------- 1 root root 166 Dec  9  2021 VC581-1_phases.csv\n",
            "-rw------- 1 root root 146 Dec  9  2021 VC581-2_phases.csv\n",
            "-rw------- 1 root root 133 Dec  9  2021 VC581-3_phases.csv\n",
            "-rw------- 1 root root 109 Dec  9  2021 VC581-5_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 VC581-6_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 VC581-7_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 VC789-3_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 VF269-7_phases.csv\n",
            "-rw------- 1 root root 135 Dec  9  2021 VH99-3_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 VM195-5_phases.csv\n",
            "-rw------- 1 root root 133 Dec  9  2021 VM195-6_phases.csv\n",
            "-rw------- 1 root root  88 Dec  9  2021 VM569-7_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 VM570-4_phases.csv\n",
            "-rw------- 1 root root 167 Dec  9  2021 VM570-8_phases.csv\n",
            "-rw------- 1 root root 137 Dec  9  2021 VN484-1_phases.csv\n",
            "-rw------- 1 root root 169 Dec  9  2021 VS321-6_phases.csv\n",
            "-rw------- 1 root root 145 Dec  9  2021 VS321-7_phases.csv\n",
            "-rw------- 1 root root 112 Dec  9  2021 VS510-2_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 VS510-7_phases.csv\n",
            "-rw------- 1 root root 158 Dec  9  2021 WA1014-3_phases.csv\n",
            "-rw------- 1 root root 125 Dec  9  2021 WA402-7_phases.csv\n",
            "-rw------- 1 root root 138 Dec  9  2021 WM472-8_phases.csv\n",
            "-rw------- 1 root root 156 Dec  9  2021 WS1048-4_phases.csv\n",
            "-rw------- 1 root root 134 Dec  9  2021 WS531-4_phases.csv\n",
            "-rw------- 1 root root 133 Dec  9  2021 ZL1077-1_phases.csv\n",
            "-rw------- 1 root root 168 Dec  9  2021 ZS435-5_phases.csv\n",
            "-rw------- 1 root root 160 Dec  9  2021 ZS435-6_phases.csv\n",
            "\n",
            "üîç Found:\n",
            "   CSV files: 704\n",
            "   TXT files: 0\n",
            "   JSON files: 0\n",
            "\n",
            "üìÑ Loading: FH658-4_phases.csv\n",
            "‚úÖ Loaded 14 annotations\n",
            "\n",
            "üìä Columns: ['tPB2', '7', '28']\n",
            "\n",
            "üëÄ First 10 rows:\n",
            "   tPB2    7   28\n",
            "0  tPNa   29   99\n",
            "1  tPNf  100  107\n",
            "2    t2  108  153\n",
            "3    t3  154  155\n",
            "4    t4  156  197\n",
            "5    t5  198  225\n",
            "6    t6  226  253\n",
            "7    t7  254  277\n",
            "8    t8  278  293\n",
            "9   t9+  294  409\n",
            "\n",
            "üè∑Ô∏è Checking for label columns...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "8MS34juqN7Em"
      },
      "id": "8MS34juqN7Em",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# LOAD DEVELOPMENTAL ANNOTATIONS & CREATE QUALITY LABELS\n",
        "# ============================================================\n",
        "print(\"üìã Loading developmental annotations and creating quality labels...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "annotations_dir = \"/content/drive/MyDrive/gfgIVF/embryo_dataset_annotations/embryo_dataset_annotations\"\n",
        "\n",
        "if os.path.exists(annotations_dir):\n",
        "    print(f\"‚úÖ Found annotations directory: {annotations_dir}\")\n",
        "\n",
        "    # Find all phase CSV files\n",
        "    import glob\n",
        "    csv_files = glob.glob(f'{annotations_dir}/*_phases.csv')\n",
        "\n",
        "    print(f\"\\nüîç Found {len(csv_files)} embryo phase files\")\n",
        "\n",
        "    if len(csv_files) == 0:\n",
        "        print(\"‚ùå No phase CSV files found!\")\n",
        "    else:\n",
        "        # Load all phase files and create quality labels\n",
        "        embryo_labels = []\n",
        "\n",
        "        print(\"\\n‚è≥ Processing phase files to derive quality labels...\")\n",
        "\n",
        "        for csv_file in tqdm(csv_files, desc=\"Loading phases\"):\n",
        "            # Extract embryo ID from filename (e.g., \"RV754-4_phases.csv\" -> \"RV754-4\")\n",
        "            embryo_id = os.path.basename(csv_file).replace('_phases.csv', '')\n",
        "\n",
        "            try:\n",
        "                # Load phase timing data\n",
        "                df_phase = pd.read_csv(csv_file)\n",
        "\n",
        "                # The CSV has developmental stages in first column and timing ranges in other columns\n",
        "                # Typical format: tPB2, tPNa, tPNf, t2, t4, t5, t6, t8 (developmental milestones)\n",
        "\n",
        "                # Calculate developmental metrics\n",
        "                # Fast development to t2 (2-cell) and t8 (8-cell) indicates good quality\n",
        "\n",
        "                # Get timing for key stages\n",
        "                stages = df_phase.iloc[:, 0].values if len(df_phase.columns) > 0 else []\n",
        "\n",
        "                # Check if embryo reached important stages\n",
        "                has_t2 = 't2' in stages\n",
        "                has_t4 = 't4' in stages\n",
        "                has_t8 = 't8' in stages\n",
        "\n",
        "                # Count how many stages reached (more stages = better development)\n",
        "                num_stages = len(stages)\n",
        "\n",
        "                # Derive quality label based on developmental progression\n",
        "                # Use median/average as threshold for balanced classes\n",
        "                # Dataset shows average ~11 stages, so use 10 as threshold\n",
        "                # This creates ~50/50 split between good and not_good\n",
        "\n",
        "                if num_stages >= 12 and has_t8:\n",
        "                    # Excellent progression: ‚â•12 stages with t8 = GOOD\n",
        "                    quality = 'good'\n",
        "                    quality_numeric = 1\n",
        "                elif num_stages >= 10 and has_t4 and has_t8:\n",
        "                    # Good progression: ‚â•10 stages with t4 and t8 = GOOD\n",
        "                    quality = 'good'\n",
        "                    quality_numeric = 1\n",
        "                else:\n",
        "                    # Below average progression = NOT GOOD\n",
        "                    quality = 'not_good'\n",
        "                    quality_numeric = 0\n",
        "\n",
        "                embryo_labels.append({\n",
        "                    'embryo_id': embryo_id,\n",
        "                    'quality': quality,\n",
        "                    'quality_numeric': quality_numeric,\n",
        "                    'num_stages': num_stages,\n",
        "                    'has_t2': has_t2,\n",
        "                    'has_t4': has_t4,\n",
        "                    'has_t8': has_t8\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error processing {embryo_id}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Create DataFrame with labels\n",
        "        df_labels = pd.DataFrame(embryo_labels)\n",
        "\n",
        "        print(f\"\\n‚úÖ Created labels for {len(df_labels)} embryos!\")\n",
        "        print(f\"\\nüìä Label Distribution:\")\n",
        "        print(df_labels['quality'].value_counts())\n",
        "        print(f\"\\n   Good:     {sum(df_labels['quality'] == 'good')} embryos ({sum(df_labels['quality'] == 'good')/len(df_labels)*100:.1f}%)\")\n",
        "        print(f\"   Not Good: {sum(df_labels['quality'] == 'not_good')} embryos ({sum(df_labels['quality'] == 'not_good')/len(df_labels)*100:.1f}%)\")\n",
        "\n",
        "        print(f\"\\nüìà Developmental Statistics:\")\n",
        "        print(f\"   Average stages reached: {df_labels['num_stages'].mean():.1f}\")\n",
        "        print(f\"   Embryos reaching t2: {sum(df_labels['has_t2'])} ({sum(df_labels['has_t2'])/len(df_labels)*100:.1f}%)\")\n",
        "        print(f\"   Embryos reaching t4: {sum(df_labels['has_t4'])} ({sum(df_labels['has_t4'])/len(df_labels)*100:.1f}%)\")\n",
        "        print(f\"   Embryos reaching t8: {sum(df_labels['has_t8'])} ({sum(df_labels['has_t8'])/len(df_labels)*100:.1f}%)\")\n",
        "\n",
        "        print(f\"\\nüëÄ Sample labels (first 10):\")\n",
        "        print(df_labels[['embryo_id', 'quality', 'num_stages']].head(10))\n",
        "\n",
        "        print(f\"\\nüí° Labeling Strategy:\")\n",
        "        print(f\"   ‚úÖ GOOD: Embryos reaching ‚â•12 stages with t8, OR ‚â•10 stages with both t4 and t8\")\n",
        "        print(f\"   ‚ùå NOT GOOD: Embryos with <10 stages or missing critical milestones\")\n",
        "        print(f\"   üìä Threshold based on dataset statistics (avg ~11 stages)\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"‚úÖ QUALITY LABELS CREATED SUCCESSFULLY!\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "else:\n",
        "    print(f\"‚ùå Annotations directory not found: {annotations_dir}\")\n",
        "    print(\"\\nüí° Looking for annotations tar.gz file to extract...\")\n",
        "\n",
        "    tar_file = \"/content/drive/MyDrive/gfgIVF/embryo_dataset_annotations.tar.gz\"\n",
        "    if os.path.exists(tar_file):\n",
        "        print(f\"‚úÖ Found: {tar_file}\")\n",
        "        print(\"Extracting...\")\n",
        "\n",
        "        import tarfile\n",
        "        extract_to = \"/content/drive/MyDrive/gfgIVF\"\n",
        "\n",
        "        with tarfile.open(tar_file, 'r:gz') as tar_ref:\n",
        "            tar_ref.extractall(extract_to)\n",
        "\n",
        "        print(\"‚úÖ Extracted! Re-run this cell to load annotations.\")\n",
        "    else:\n",
        "        print(\"‚ùå Annotations file not found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw1-aYAMNmJX",
        "outputId": "ad7929a8-d6a5-431d-e1f2-045874170daa"
      },
      "id": "Hw1-aYAMNmJX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Loading developmental annotations and creating quality labels...\n",
            "============================================================\n",
            "‚úÖ Found annotations directory: /content/drive/MyDrive/gfgIVF/embryo_dataset_annotations/embryo_dataset_annotations\n",
            "\n",
            "üîç Found 704 embryo phase files\n",
            "\n",
            "‚è≥ Processing phase files to derive quality labels...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading phases: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 704/704 [00:15<00:00, 46.71it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Created labels for 704 embryos!\n",
            "\n",
            "üìä Label Distribution:\n",
            "quality\n",
            "good        475\n",
            "not_good    229\n",
            "Name: count, dtype: int64\n",
            "\n",
            "   Good:     475 embryos (67.5%)\n",
            "   Not Good: 229 embryos (32.5%)\n",
            "\n",
            "üìà Developmental Statistics:\n",
            "   Average stages reached: 11.0\n",
            "   Embryos reaching t2: 685 (97.3%)\n",
            "   Embryos reaching t4: 649 (92.2%)\n",
            "   Embryos reaching t8: 601 (85.4%)\n",
            "\n",
            "üëÄ Sample labels (first 10):\n",
            "    embryo_id   quality  num_stages\n",
            "0     FH658-4      good          14\n",
            "1    GC381-10  not_good          13\n",
            "2     DM235-3      good          10\n",
            "3     EJ393-3      good          11\n",
            "4   GF667-1-1  not_good           9\n",
            "5     FD156-4      good          12\n",
            "6     DA925-6      good          13\n",
            "7  DHDPI042-3  not_good           9\n",
            "8    FE14-020  not_good           6\n",
            "9     DY236-4  not_good           7\n",
            "\n",
            "üí° Labeling Strategy:\n",
            "   ‚úÖ GOOD: Embryos reaching ‚â•12 stages with t8, OR ‚â•10 stages with both t4 and t8\n",
            "   ‚ùå NOT GOOD: Embryos with <10 stages or missing critical milestones\n",
            "   üìä Threshold based on dataset statistics (avg ~11 stages)\n",
            "\n",
            "============================================================\n",
            "‚úÖ QUALITY LABELS CREATED SUCCESSFULLY!\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a6aeb6f",
      "metadata": {
        "id": "2a6aeb6f"
      },
      "source": [
        "---\n",
        "## 4Ô∏è‚É£ Feature Extraction Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "833bb1fa",
      "metadata": {
        "id": "833bb1fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c8700b-096c-4ef6-ba7f-6a9a7ee607ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Feature extraction functions loaded!\n",
            "\n",
            "üìä Total features per IMAGE: 20\n",
            "   - 8 morphological features √ó 2 (mean + std) = 16 features\n",
            "   - 4 temporal features (set to 0 for static images) = 4 features\n",
            "\n",
            "üí° IMPORTANT: This notebook processes STATIC IMAGES from time-lapse sequences\n",
            "   - Each image is processed individually (not as video)\n",
            "   - Temporal features = 0 (no frame-to-frame motion data)\n",
            "   - Std values = 0 (only one frame per image)\n"
          ]
        }
      ],
      "source": [
        "def extract_frame_features(frame):\n",
        "    \"\"\"\n",
        "    Extract 8 morphological features from a single frame\n",
        "    \"\"\"\n",
        "    # Convert to grayscale\n",
        "    if len(frame.shape) == 3:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = frame\n",
        "\n",
        "    features = {}\n",
        "\n",
        "    # 1. Standard deviation (fragmentation indicator)\n",
        "    features['std_dev'] = float(np.std(gray))\n",
        "\n",
        "    # 2. Mean intensity (brightness)\n",
        "    features['mean_intensity'] = float(np.mean(gray))\n",
        "\n",
        "    # 3. Contrast\n",
        "    features['contrast'] = float(gray.max() - gray.min())\n",
        "\n",
        "    # 4. Entropy (texture uniformity)\n",
        "    hist, _ = np.histogram(gray, bins=256, range=(0, 256))\n",
        "    hist = hist / (hist.sum() + 1e-10)\n",
        "    hist = hist[hist > 0]\n",
        "    features['entropy'] = float(-np.sum(hist * np.log2(hist)))\n",
        "\n",
        "    # 5. Edge density\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "    features['edge_density'] = float(np.sum(edges > 0) / edges.size)\n",
        "\n",
        "    # 6. Number of regions (blob count)\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    features['num_regions'] = len(contours)\n",
        "\n",
        "    # 7. Circularity\n",
        "    if len(contours) > 0:\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        area = cv2.contourArea(largest_contour)\n",
        "        perimeter = cv2.arcLength(largest_contour, True)\n",
        "        if perimeter > 0:\n",
        "            features['circularity'] = float(4 * np.pi * area / (perimeter ** 2))\n",
        "        else:\n",
        "            features['circularity'] = 0.0\n",
        "    else:\n",
        "        features['circularity'] = 0.0\n",
        "\n",
        "    # 8. Gradient magnitude\n",
        "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "    features['gradient_magnitude'] = float(np.mean(np.sqrt(sobelx**2 + sobely**2)))\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_temporal_features(frames):\n",
        "    \"\"\"\n",
        "    Extract 4 temporal features from video sequence\n",
        "    \"\"\"\n",
        "    temporal_features = {}\n",
        "\n",
        "    if len(frames) < 2:\n",
        "        # Not enough frames for temporal analysis\n",
        "        temporal_features['mean_motion'] = 0.0\n",
        "        temporal_features['std_motion'] = 0.0\n",
        "        temporal_features['max_motion'] = 0.0\n",
        "        temporal_features['development_speed'] = 0.0\n",
        "        return temporal_features\n",
        "\n",
        "    # Calculate frame-to-frame differences\n",
        "    frame_diffs = []\n",
        "    for i in range(1, len(frames)):\n",
        "        diff = np.mean(np.abs(frames[i].astype(float) - frames[i-1].astype(float)))\n",
        "        frame_diffs.append(diff)\n",
        "\n",
        "    # Temporal features\n",
        "    temporal_features['mean_motion'] = float(np.mean(frame_diffs))\n",
        "    temporal_features['std_motion'] = float(np.std(frame_diffs))\n",
        "    temporal_features['max_motion'] = float(np.max(frame_diffs))\n",
        "    temporal_features['development_speed'] = float(np.sum(frame_diffs) / len(frame_diffs))\n",
        "\n",
        "    return temporal_features\n",
        "\n",
        "\n",
        "def process_video(video_path, sample_frames=10):\n",
        "    \"\"\"\n",
        "    Process a video and extract all 20 features\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        if total_frames == 0:\n",
        "            cap.release()\n",
        "            return None\n",
        "\n",
        "        # Sample frames evenly throughout video\n",
        "        sample_frames = min(sample_frames, total_frames)\n",
        "        frame_indices = np.linspace(0, total_frames-1, sample_frames, dtype=int)\n",
        "\n",
        "        sampled_frames = []\n",
        "        frame_features_list = []\n",
        "\n",
        "        for idx in frame_indices:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
        "            ret, frame = cap.read()\n",
        "            if ret and frame is not None:\n",
        "                # Convert to grayscale for temporal analysis\n",
        "                if len(frame.shape) == 3:\n",
        "                    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                else:\n",
        "                    gray_frame = frame\n",
        "                sampled_frames.append(gray_frame)\n",
        "\n",
        "                # Extract morphological features\n",
        "                frame_features_list.append(extract_frame_features(frame))\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        if len(frame_features_list) == 0:\n",
        "            return None\n",
        "\n",
        "        # Aggregate morphological features (mean and std across frames)\n",
        "        aggregated_features = {}\n",
        "        for key in frame_features_list[0].keys():\n",
        "            values = [f[key] for f in frame_features_list]\n",
        "            aggregated_features[f'{key}_mean'] = float(np.mean(values))\n",
        "            aggregated_features[f'{key}_std'] = float(np.std(values))\n",
        "\n",
        "        # Add temporal features\n",
        "        temporal_features = extract_temporal_features(sampled_frames)\n",
        "        aggregated_features.update(temporal_features)\n",
        "\n",
        "        return aggregated_features\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {video_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def process_image(image_path):\n",
        "    \"\"\"\n",
        "    Process a single image and extract 8 morphological features\n",
        "    For images (not videos), we don't have temporal features\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read image\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            return None\n",
        "\n",
        "        # Extract features from single image\n",
        "        features = extract_frame_features(img)\n",
        "\n",
        "        # Since no temporal data, set temporal features to 0\n",
        "        features['mean_motion'] = 0.0\n",
        "        features['std_motion'] = 0.0\n",
        "        features['max_motion'] = 0.0\n",
        "        features['development_speed'] = 0.0\n",
        "\n",
        "        # For images, we only have one frame, so mean = value, std = 0\n",
        "        final_features = {}\n",
        "        for key, value in features.items():\n",
        "            if key not in ['mean_motion', 'std_motion', 'max_motion', 'development_speed']:\n",
        "                final_features[f'{key}_mean'] = value\n",
        "                final_features[f'{key}_std'] = 0.0\n",
        "\n",
        "        # Add temporal features\n",
        "        final_features['mean_motion'] = 0.0\n",
        "        final_features['std_motion'] = 0.0\n",
        "        final_features['max_motion'] = 0.0\n",
        "        final_features['development_speed'] = 0.0\n",
        "\n",
        "        return final_features\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"‚úÖ Feature extraction functions loaded!\")\n",
        "print(\"\\nüìä Total features per IMAGE: 20\")\n",
        "print(\"   - 8 morphological features √ó 2 (mean + std) = 16 features\")\n",
        "print(\"   - 4 temporal features (set to 0 for static images) = 4 features\")\n",
        "print(\"\\nüí° IMPORTANT: This notebook processes STATIC IMAGES from time-lapse sequences\")\n",
        "\n",
        "print(\"   - Each image is processed individually (not as video)\")\n",
        "print(\"   - Temporal features = 0 (no frame-to-frame motion data)\")\n",
        "print(\"   - Std values = 0 (only one frame per image)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f852c54",
      "metadata": {
        "id": "7f852c54"
      },
      "source": [
        "---\n",
        "## 5Ô∏è‚É£ Test Feature Extraction (Single Video)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5Q_lmliYQH6u"
      },
      "id": "5Q_lmliYQH6u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e329ecd",
      "metadata": {
        "id": "1e329ecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b870e38-3f19-40eb-f781-0ccb284fac71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Testing feature extraction on: /content/drive/MyDrive/gfgIVF/embryo_data/embryo_dataset_F-45/PA145-1/D2013.02.11_S0732_I132_WELL1_RUN275.jpeg\n",
            "\n",
            "‚úÖ Feature extraction successful!\n",
            "\n",
            "üìä Extracted 20 features:\n",
            "    1. std_dev_mean             : 27.5739\n",
            "    2. std_dev_std              : 0.0000\n",
            "    3. mean_intensity_mean      : 46.0493\n",
            "    4. mean_intensity_std       : 0.0000\n",
            "    5. contrast_mean            : 160.0000\n",
            "    6. contrast_std             : 0.0000\n",
            "    7. entropy_mean             : 5.7694\n",
            "    8. entropy_std              : 0.0000\n",
            "    9. edge_density_mean        : 0.0139\n",
            "   10. edge_density_std         : 0.0000\n",
            "   11. num_regions_mean         : 48.0000\n",
            "   12. num_regions_std          : 0.0000\n",
            "   13. circularity_mean         : 0.2183\n",
            "   14. circularity_std          : 0.0000\n",
            "   15. gradient_magnitude_mean  : 12.9490\n",
            "   16. gradient_magnitude_std   : 0.0000\n",
            "   17. mean_motion              : 0.0000\n",
            "   18. std_motion               : 0.0000\n",
            "   19. max_motion               : 0.0000\n",
            "   20. development_speed        : 0.0000\n"
          ]
        }
      ],
      "source": [
        "# Test on first image\n",
        "try:\n",
        "    if len(image_files) > 0:\n",
        "        print(f\"üß™ Testing feature extraction on: {image_files[0]}\")\n",
        "        test_features = process_image(image_files[0])\n",
        "\n",
        "        if test_features:\n",
        "            print(\"\\n‚úÖ Feature extraction successful!\")\n",
        "            print(f\"\\nüìä Extracted {len(test_features)} features:\")\n",
        "            for i, (key, value) in enumerate(test_features.items(), 1):\n",
        "                print(f\"   {i:2d}. {key:25s}: {value:.4f}\")\n",
        "        else:\n",
        "            print(\"\\n‚ùå Feature extraction failed!\")\n",
        "    else:\n",
        "\n",
        "        print(\"‚ö†Ô∏è No images available for testing!\")\n",
        "        print(\"\\nüëâ Go back and run Cell 11 now!\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"   4. Cell 15 - Test feature extraction (THIS CELL)\")\n",
        "\n",
        "    print(\"‚ùå ERROR: 'image_files' variable not found!\")\n",
        "    print(\"   3. Cell 13 - Load feature extraction functions\")\n",
        "\n",
        "    print(\"\\nüìã You must run Cell 11 (Find Images) FIRST before this cell.\")\n",
        "    print(\"   2. Cell 11 - Find all images (creates 'image_files' variable)\")\n",
        "\n",
        "    print(\"\\nCorrect cell order:\")\n",
        "    print(\"   1. Cell 7  - Extract dataset from Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f68b9b8",
      "metadata": {
        "id": "7f68b9b8"
      },
      "source": [
        "---\n",
        "## 6Ô∏è‚É£ Process All Image & Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c96129f",
      "metadata": {
        "id": "0c96129f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413d47dc-fcb9-472b-9997-60e831127090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñºÔ∏è Processing all images with quality labels...\n",
            "Total images to process: 211248\n",
            "Total embryos with labels: 704\n",
            "\n",
            "‚è≥ This may take 30-60 minutes for 163K images...\n",
            "\n",
            "üíæ Checkpoint system enabled (saves every 10,000 images)\n",
            "   If interrupted, re-run this cell to resume automatically!\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images:  32%|‚ñà‚ñà‚ñà‚ñè      | 66695/211248 [5:40:02<11:13:54,  3.57it/s]"
          ]
        }
      ],
      "source": [
        "# Process all images with labels from developmental data\n",
        "print(\"üñºÔ∏è Processing all images with quality labels...\")\n",
        "print(f\"Total images to process: {len(image_files)}\")\n",
        "print(f\"Total embryos with labels: {len(df_labels)}\")\n",
        "print(\"\\n‚è≥ This may take 30-60 minutes for 163K images...\\n\")\n",
        "\n",
        "# Checkpoint configuration\n",
        "checkpoint_file = f'checkpoint_{FOCAL_PLANE}.pkl'\n",
        "checkpoint_interval = 10000  # Save checkpoint every 10,000 images\n",
        "\n",
        "all_features = []\n",
        "all_labels = []\n",
        "image_ids = []\n",
        "skipped_no_label = 0\n",
        "start_index = 0\n",
        "\n",
        "# Check if checkpoint exists (resume from previous run)\n",
        "if os.path.exists(checkpoint_file):\n",
        "    print(\"üîÑ CHECKPOINT FOUND! Resuming from previous run...\")\n",
        "    checkpoint_data = joblib.load(checkpoint_file)\n",
        "\n",
        "    all_features = checkpoint_data['all_features']\n",
        "    all_labels = checkpoint_data['all_labels']\n",
        "    image_ids = checkpoint_data['image_ids']\n",
        "    skipped_no_label = checkpoint_data['skipped_no_label']\n",
        "    start_index = checkpoint_data['last_index'] + 1\n",
        "\n",
        "    print(f\"   ‚úÖ Loaded checkpoint: {len(all_features)} images already processed\")\n",
        "    print(f\"   ‚ñ∂Ô∏è Resuming from image #{start_index + 1}\")\n",
        "    print()\n",
        "else:\n",
        "    print(\"üíæ Checkpoint system enabled (saves every 10,000 images)\")\n",
        "    print(\"   If interrupted, re-run this cell to resume automatically!\\n\")\n",
        "\n",
        "# Create quick lookup dictionary for faster access\n",
        "label_dict = dict(zip(df_labels['embryo_id'], df_labels['quality_numeric']))\n",
        "\n",
        "# Process images with checkpoint support\n",
        "for idx in tqdm(range(start_index, len(image_files)),\n",
        "                desc=\"Processing images\",\n",
        "                initial=start_index,\n",
        "                total=len(image_files)):\n",
        "\n",
        "    image_path = image_files[idx]\n",
        "\n",
        "    # Extract features\n",
        "    features = process_image(image_path)\n",
        "\n",
        "    if features is None:\n",
        "        continue\n",
        "\n",
        "    # Get embryo ID from folder name\n",
        "    # Image path format: /path/to/embryo_data/embryo_dataset_F-45/RV754-4/image.jpeg\n",
        "    embryo_id = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "    # Look up label from df_labels\n",
        "    if embryo_id in label_dict:\n",
        "        label = label_dict[embryo_id]  # 0 or 1\n",
        "    else:\n",
        "        # Skip images without labels\n",
        "        skipped_no_label += 1\n",
        "        continue\n",
        "\n",
        "    # Store results\n",
        "    image_id = os.path.basename(image_path)\n",
        "    all_features.append(features)\n",
        "    all_labels.append(label)\n",
        "    image_ids.append(f\"{embryo_id}/{image_id}\")\n",
        "\n",
        "    # Save checkpoint periodically\n",
        "    if (idx + 1) % checkpoint_interval == 0:\n",
        "        checkpoint_data = {\n",
        "            'all_features': all_features,\n",
        "            'all_labels': all_labels,\n",
        "            'image_ids': image_ids,\n",
        "            'skipped_no_label': skipped_no_label,\n",
        "            'last_index': idx\n",
        "        }\n",
        "        joblib.dump(checkpoint_data, checkpoint_file)\n",
        "        # Print checkpoint saved message (tqdm will overwrite it)\n",
        "\n",
        "# Save final checkpoint\n",
        "checkpoint_data = {\n",
        "    'all_features': all_features,\n",
        "    'all_labels': all_labels,\n",
        "    'image_ids': image_ids,\n",
        "    'skipped_no_label': skipped_no_label,\n",
        "    'last_index': len(image_files) - 1\n",
        "}\n",
        "joblib.dump(checkpoint_data, checkpoint_file)\n",
        "\n",
        "# Create DataFrame\n",
        "df_features = pd.DataFrame(all_features)\n",
        "df_features['label'] = all_labels\n",
        "df_features['image_id'] = image_ids\n",
        "\n",
        "print(f\"\\n‚úÖ Successfully processed {len(df_features)} images!\")\n",
        "print(f\"‚ö†Ô∏è Skipped {skipped_no_label} images (no embryo label found)\")\n",
        "print(f\"\\nüìä Dataset shape: {df_features.shape}\")\n",
        "print(f\"\\nüìà Class distribution:\")\n",
        "print(df_features['label'].value_counts())\n",
        "print(f\"\\n   Class 0 (Not Good): {sum(df_features['label'] == 0)} ({sum(df_features['label'] == 0)/len(df_features)*100:.1f}%)\")\n",
        "print(f\"   Class 1 (Good):     {sum(df_features['label'] == 1)} ({sum(df_features['label'] == 1)/len(df_features)*100:.1f}%)\")\n",
        "print(f\"\\nüîç First 5 rows:\")\n",
        "print(df_features.head())\n",
        "print(f\"\\nüí° Labels assigned based on embryo developmental progression:\")\n",
        "print(f\"   Good = ‚â•12 stages with t8, OR ‚â•10 stages with both t4 and t8\")\n",
        "print(f\"   Not Good = <10 stages or missing critical milestones (t4/t8)\")\n",
        "print(f\"\\nüíæ Checkpoint saved: {checkpoint_file}\")\n",
        "print(f\"   (Will be auto-deleted after Cell 21 saves CSV)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76e07435",
      "metadata": {
        "id": "76e07435"
      },
      "source": [
        "---\n",
        "## 7Ô∏è‚É£ Save Processed Dataset (Optional Checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c883f6a7",
      "metadata": {
        "id": "c883f6a7"
      },
      "outputs": [],
      "source": [
        "# Save processed features (checkpoint)\n",
        "df_features.to_csv(f'processed_features_{FOCAL_PLANE}.csv', index=False)\n",
        "print(f\"‚úÖ Saved: processed_features_{FOCAL_PLANE}.csv\")\n",
        "print(\"üí° You can restart from here if notebook crashes!\")\n",
        "\n",
        "# Clean up processing checkpoint (no longer needed)\n",
        "checkpoint_file = f'checkpoint_{FOCAL_PLANE}.pkl'\n",
        "if os.path.exists(checkpoint_file):\n",
        "    os.remove(checkpoint_file)\n",
        "    print(f\"üóëÔ∏è Removed processing checkpoint (data now saved in CSV)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "894b8a5b",
      "metadata": {
        "id": "894b8a5b"
      },
      "source": [
        "---\n",
        "## 8Ô∏è‚É£ Train Model with SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23d1fa52",
      "metadata": {
        "id": "23d1fa52"
      },
      "outputs": [],
      "source": [
        "# Prepare training data\n",
        "print(\"üìä Preparing training data...\")\n",
        "\n",
        "# Drop non-feature columns\n",
        "X = df_features.drop(['label', 'image_id'], axis=1)  # Changed from 'video_id' to 'image_id'\n",
        "y = df_features['label']\n",
        "\n",
        "# Save feature names for later use\n",
        "feature_names = list(X.columns)\n",
        "print(f\"\\n‚úÖ Feature names ({len(feature_names)}):\")\n",
        "for i, name in enumerate(feature_names, 1):\n",
        "    print(f\"   {i:2d}. {name}\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä Data split:\")\n",
        "print(f\"   Training set: {len(X_train)} samples\")\n",
        "print(f\"   Test set: {len(X_test)} samples\")\n",
        "print(f\"\\n   Training class distribution:\")\n",
        "print(f\"   - Class 0: {sum(y_train == 0)}\")\n",
        "print(f\"   - Class 1: {sum(y_train == 1)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46eb9f18",
      "metadata": {
        "id": "46eb9f18"
      },
      "outputs": [],
      "source": [
        "# Scale features\n",
        "print(\"‚öôÔ∏è Scaling features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"‚úÖ Features scaled!\")\n",
        "\n",
        "# Apply SMOTE to balance classes\n",
        "print(\"\\n‚öñÔ∏è Applying SMOTE to balance classes...\")\n",
        "min_class_samples = min(sum(y_train == 0), sum(y_train == 1))\n",
        "k_neighbors = min(3, min_class_samples - 1) if min_class_samples > 1 else 1\n",
        "\n",
        "smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"\\nüìä After SMOTE:\")\n",
        "print(f\"   Class 0: {sum(y_train_balanced == 0)}\")\n",
        "print(f\"   Class 1: {sum(y_train_balanced == 1)}\")\n",
        "print(\"‚úÖ Classes balanced!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ecf1f7",
      "metadata": {
        "id": "49ecf1f7"
      },
      "outputs": [],
      "source": [
        "# Train Random Forest\n",
        "print(\"\\nüå≤ Training Random Forest Classifier...\")\n",
        "print(\"‚è≥ This may take 5-10 minutes...\\n\")\n",
        "\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=200,        # More trees = better performance\n",
        "    max_depth=10,            # Deeper trees for complex patterns\n",
        "    min_samples_leaf=2,\n",
        "    min_samples_split=4,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1,               # Use all CPU cores\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "print(\"\\n‚úÖ Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60f8c2ea",
      "metadata": {
        "id": "60f8c2ea"
      },
      "source": [
        "---\n",
        "## 9Ô∏è‚É£ Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b31a4b1f",
      "metadata": {
        "id": "b31a4b1f"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "# Print results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"üìä MODEL EVALUATION - {FOCAL_PLANE}\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_test, y_pred,\n",
        "                          target_names=['Not Good', 'Good'],\n",
        "                          digits=3))\n",
        "\n",
        "print(f\"\\nüéØ Summary Metrics:\")\n",
        "print(f\"   Accuracy:  {accuracy:.2%}\")\n",
        "print(f\"   Precision: {precision:.2%}\")\n",
        "print(f\"   Recall:    {recall:.2%}\")\n",
        "print(f\"   F1-Score:  {f1:.2%}\")\n",
        "print(f\"   AUC-ROC:   {auc:.3f}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6f440e3",
      "metadata": {
        "id": "f6f440e3"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Not Good', 'Good'],\n",
        "            yticklabels=['Not Good', 'Good'],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title(f'Confusion Matrix - {FOCAL_PLANE}\\nAccuracy: {accuracy:.2%}',\n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'confusion_matrix_{FOCAL_PLANE}.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úÖ Saved: confusion_matrix_{FOCAL_PLANE}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80a54bc7",
      "metadata": {
        "id": "80a54bc7"
      },
      "outputs": [],
      "source": [
        "# Feature Importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "# Plot top 15 features\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features = feature_importance.head(15)\n",
        "sns.barplot(data=top_features, x='importance', y='feature', palette='viridis')\n",
        "plt.title(f'Top 15 Feature Importances - {FOCAL_PLANE}',\n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Importance', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'feature_importance_{FOCAL_PLANE}.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úÖ Saved: feature_importance_{FOCAL_PLANE}.png\")\n",
        "print(f\"\\nüìä Top 10 Most Important Features:\")\n",
        "print(feature_importance.head(10).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e8b08e0",
      "metadata": {
        "id": "2e8b08e0"
      },
      "source": [
        "---\n",
        "## üîü Save Model & All Required Outputs\n",
        "\n",
        "### ‚ö†Ô∏è IMPORTANT: These 5 files are REQUIRED for ensemble model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1cea7c2",
      "metadata": {
        "id": "c1cea7c2"
      },
      "outputs": [],
      "source": [
        "print(\"üíæ Saving all required outputs...\\n\")\n",
        "\n",
        "# 1. Save trained model\n",
        "model_filename = f'embryo_model_{FOCAL_PLANE}.pkl'\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"‚úÖ 1/5: Saved {model_filename}\")\n",
        "\n",
        "# 2. Save scaler\n",
        "scaler_filename = f'scaler_{FOCAL_PLANE}.pkl'\n",
        "joblib.dump(scaler, scaler_filename)\n",
        "print(f\"‚úÖ 2/5: Saved {scaler_filename}\")\n",
        "\n",
        "# 3. Save feature names\n",
        "feature_names_filename = f'feature_names_{FOCAL_PLANE}.json'\n",
        "with open(feature_names_filename, 'w') as f:\n",
        "    json.dump(feature_names, f, indent=2)\n",
        "print(f\"‚úÖ 3/5: Saved {feature_names_filename}\")\n",
        "\n",
        "# 4. Save evaluation results\n",
        "results = {\n",
        "    'focal_plane': FOCAL_PLANE,\n",
        "    'dataset_size': len(df_features),\n",
        "    'train_size': len(X_train),\n",
        "    'test_size': len(X_test),\n",
        "    'accuracy': float(accuracy),\n",
        "    'precision': float(precision),\n",
        "    'recall': float(recall),\n",
        "    'f1_score': float(f1),\n",
        "    'auc_roc': float(auc),\n",
        "    'confusion_matrix': cm.tolist(),\n",
        "    'class_distribution': {\n",
        "        'class_0': int(sum(y == 0)),\n",
        "        'class_1': int(sum(y == 1))\n",
        "    },\n",
        "    'top_10_features': feature_importance.head(10).to_dict('records'),\n",
        "    'model_params': {\n",
        "        'n_estimators': 200,\n",
        "        'max_depth': 10,\n",
        "        'random_state': 42\n",
        "    }\n",
        "}\n",
        "\n",
        "results_filename = f'results_{FOCAL_PLANE}.json'\n",
        "with open(results_filename, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "print(f\"‚úÖ 4/5: Saved {results_filename}\")\n",
        "\n",
        "# 5. Confusion matrix already saved above\n",
        "print(f\"‚úÖ 5/5: confusion_matrix_{FOCAL_PLANE}.png (already saved)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ ALL OUTPUTS SAVED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d562b2c6",
      "metadata": {
        "id": "d562b2c6"
      },
      "source": [
        "---\n",
        "## 1Ô∏è‚É£1Ô∏è‚É£ Download All Files to Your Computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c107da",
      "metadata": {
        "id": "a8c107da"
      },
      "outputs": [],
      "source": [
        "print(\"üì• Downloading all required files...\\n\")\n",
        "\n",
        "# List of files to download\n",
        "files_to_download = [\n",
        "    f'embryo_model_{FOCAL_PLANE}.pkl',\n",
        "    f'scaler_{FOCAL_PLANE}.pkl',\n",
        "    f'feature_names_{FOCAL_PLANE}.json',\n",
        "    f'results_{FOCAL_PLANE}.json',\n",
        "    f'confusion_matrix_{FOCAL_PLANE}.png',\n",
        "    f'feature_importance_{FOCAL_PLANE}.png'\n",
        "]\n",
        "\n",
        "for filename in files_to_download:\n",
        "    if os.path.exists(filename):\n",
        "        files.download(filename)\n",
        "        print(f\"‚úÖ Downloaded: {filename}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è File not found: {filename}\")\n",
        "\n",
        "print(\"\\n‚úÖ All files downloaded to your Downloads folder!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "732b9688",
      "metadata": {
        "id": "732b9688"
      },
      "source": [
        "---\n",
        "## üìã Training Complete - Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adcc1a5f",
      "metadata": {
        "id": "adcc1a5f"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ TRAINING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüìä Final Results for {FOCAL_PLANE}:\")\n",
        "print(f\"   Dataset Size:     {len(df_features)} videos\")\n",
        "print(f\"   Accuracy:         {accuracy:.2%}\")\n",
        "print(f\"   Recall (Good):    {recall:.2%}\")\n",
        "print(f\"   AUC-ROC:          {auc:.3f}\")\n",
        "print(f\"\\nüì¶ Files Generated:\")\n",
        "for i, filename in enumerate(files_to_download, 1):\n",
        "    print(f\"   {i}. {filename}\")\n",
        "print(f\"\\nüöÄ Next Steps:\")\n",
        "print(f\"   1. Upload these files to shared Google Drive\")\n",
        "print(f\"   2. Share results with team\")\n",
        "print(f\"   3. Wait for Members 2 & 3 to complete training\")\n",
        "print(f\"   4. Member 4 will create ensemble model\")\n",
        "print(f\"   5. Expected ensemble accuracy: 85-90%\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if accuracy >= 0.80:\n",
        "    print(\"\\nüèÜ Excellent performance! Model is ready for ensemble!\")\n",
        "elif accuracy >= 0.70:\n",
        "    print(\"\\n‚úÖ Good performance! Ready to combine with other models.\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Performance could be improved. Check dataset quality.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0we_mFr6Ahbo"
      },
      "id": "0we_mFr6Ahbo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}